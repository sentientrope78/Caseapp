{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNTt/xAbFMWWUM+3zwOjkZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sentientrope78/Caseapp/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPntWLMzHujW",
        "outputId": "44c16554-b459-4832-80a2-8617430e2369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: [[1]\n",
            " [9]\n",
            " [6]\n",
            " [3]\n",
            " [2]\n",
            " [4]\n",
            " [8]\n",
            " [5]]\n",
            "Y_train: [ 1 81 36  9  4 16 64 25]\n",
            "X_test: [[7]\n",
            " [0]]\n",
            "Y_test: [49  0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 29.0844 - mae: 29.0844\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 28.8384 - mae: 28.8384\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 28.5929 - mae: 28.5929\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 28.3475 - mae: 28.3475\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 28.1023 - mae: 28.1023\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 27.8571 - mae: 27.8571\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 27.6115 - mae: 27.6115\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 27.3654 - mae: 27.3654\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 27.1185 - mae: 27.1185\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 26.8705 - mae: 26.8705\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 26.6212 - mae: 26.6212\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 26.3704 - mae: 26.3704\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 26.1178 - mae: 26.1178\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 25.8632 - mae: 25.8632\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 25.6065 - mae: 25.6065\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 25.3652 - mae: 25.3652\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 25.1223 - mae: 25.1223\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 24.8774 - mae: 24.8774\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 24.6301 - mae: 24.6301\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 24.3804 - mae: 24.3804\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 24.1278 - mae: 24.1278\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 23.8722 - mae: 23.8722\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 23.6133 - mae: 23.6133\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 23.3509 - mae: 23.3509\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 23.0847 - mae: 23.0847\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 22.8146 - mae: 22.8146\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 22.5403 - mae: 22.5403\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 22.2616 - mae: 22.2616\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 21.9782 - mae: 21.9782\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 21.6901 - mae: 21.6901\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 21.3968 - mae: 21.3968\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 21.1006 - mae: 21.1006\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 20.8369 - mae: 20.8369\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 20.5705 - mae: 20.5705\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 20.3008 - mae: 20.3008\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 20.0276 - mae: 20.0276\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 19.7504 - mae: 19.7504\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 19.4690 - mae: 19.4690\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 19.1830 - mae: 19.1830\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 18.8922 - mae: 18.8922\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 18.5962 - mae: 18.5962\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 18.2948 - mae: 18.2948\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 17.9877 - mae: 17.9877\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 17.6746 - mae: 17.6746\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 17.3554 - mae: 17.3554\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.0362 - mae: 17.0362\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 16.7757 - mae: 16.7757\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 16.5136 - mae: 16.5136\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 16.2494 - mae: 16.2494\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 15.9828 - mae: 15.9828\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 15.7133 - mae: 15.7133\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 15.4406 - mae: 15.4406\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 15.1641 - mae: 15.1641\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 14.8837 - mae: 14.8837\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 14.5989 - mae: 14.5989\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 14.3094 - mae: 14.3094\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 14.0150 - mae: 14.0150\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 13.7346 - mae: 13.7346\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 13.5352 - mae: 13.5352\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 13.3373 - mae: 13.3373\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 13.1402 - mae: 13.1402\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 12.9435 - mae: 12.9435\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 12.7468 - mae: 12.7468\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 12.5497 - mae: 12.5497\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 12.3517 - mae: 12.3517\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 12.1526 - mae: 12.1526\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 11.9520 - mae: 11.9520\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 11.7496 - mae: 11.7496\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 11.5451 - mae: 11.5451\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 11.4429 - mae: 11.4429\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 11.3597 - mae: 11.3597\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 11.2787 - mae: 11.2787\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 11.1998 - mae: 11.1998\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 11.1226 - mae: 11.1226\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 11.0469 - mae: 11.0469\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 10.9726 - mae: 10.9726\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 10.8993 - mae: 10.8993\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10.8269 - mae: 10.8269\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 10.7552 - mae: 10.7552\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 10.6841 - mae: 10.6841\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 10.6133 - mae: 10.6133\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 10.5428 - mae: 10.5428\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 10.4739 - mae: 10.4739\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.4927 - mae: 10.4927\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 10.5045 - mae: 10.5045\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10.5100 - mae: 10.5100\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.5099 - mae: 10.5099\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.5047 - mae: 10.5047\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 10.4949 - mae: 10.4949\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 10.4811 - mae: 10.4811\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.4636 - mae: 10.4636\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 10.4429 - mae: 10.4429\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 10.4194 - mae: 10.4194\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 10.3933 - mae: 10.3933\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 10.3651 - mae: 10.3651\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 10.3349 - mae: 10.3349\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 10.3030 - mae: 10.3030\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.2697 - mae: 10.2697\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 10.2352 - mae: 10.2352\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 10.1996 - mae: 10.1996\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 3.9046 - mae: 3.9046\n",
            "Epoch 1/300\n",
            "1/1 - 0s - 27ms/step - loss: 10.1631 - mae: 10.1631\n",
            "Epoch 2/300\n",
            "1/1 - 0s - 30ms/step - loss: 10.1258 - mae: 10.1258\n",
            "Epoch 3/300\n",
            "1/1 - 0s - 58ms/step - loss: 10.1174 - mae: 10.1174\n",
            "Epoch 4/300\n",
            "1/1 - 0s - 28ms/step - loss: 10.1184 - mae: 10.1184\n",
            "Epoch 5/300\n",
            "1/1 - 0s - 32ms/step - loss: 10.1123 - mae: 10.1123\n",
            "Epoch 6/300\n",
            "1/1 - 0s - 36ms/step - loss: 10.0997 - mae: 10.0997\n",
            "Epoch 7/300\n",
            "1/1 - 0s - 40ms/step - loss: 10.0812 - mae: 10.0812\n",
            "Epoch 8/300\n",
            "1/1 - 0s - 35ms/step - loss: 10.0573 - mae: 10.0573\n",
            "Epoch 9/300\n",
            "1/1 - 0s - 36ms/step - loss: 10.0284 - mae: 10.0284\n",
            "Epoch 10/300\n",
            "1/1 - 0s - 53ms/step - loss: 9.9950 - mae: 9.9950\n",
            "Epoch 11/300\n",
            "1/1 - 0s - 57ms/step - loss: 9.9573 - mae: 9.9573\n",
            "Epoch 12/300\n",
            "1/1 - 0s - 27ms/step - loss: 9.9458 - mae: 9.9458\n",
            "Epoch 13/300\n",
            "1/1 - 0s - 28ms/step - loss: 9.9385 - mae: 9.9385\n",
            "Epoch 14/300\n",
            "1/1 - 0s - 28ms/step - loss: 9.9274 - mae: 9.9274\n",
            "Epoch 15/300\n",
            "1/1 - 0s - 28ms/step - loss: 9.9129 - mae: 9.9129\n",
            "Epoch 16/300\n",
            "1/1 - 0s - 57ms/step - loss: 9.8954 - mae: 9.8954\n",
            "Epoch 17/300\n",
            "1/1 - 0s - 29ms/step - loss: 9.8751 - mae: 9.8751\n",
            "Epoch 18/300\n",
            "1/1 - 0s - 29ms/step - loss: 9.8525 - mae: 9.8525\n",
            "Epoch 19/300\n",
            "1/1 - 0s - 37ms/step - loss: 9.8277 - mae: 9.8277\n",
            "Epoch 20/300\n",
            "1/1 - 0s - 59ms/step - loss: 9.8010 - mae: 9.8010\n",
            "Epoch 21/300\n",
            "1/1 - 0s - 58ms/step - loss: 9.7727 - mae: 9.7727\n",
            "Epoch 22/300\n",
            "1/1 - 0s - 27ms/step - loss: 9.7541 - mae: 9.7541\n",
            "Epoch 23/300\n",
            "1/1 - 0s - 28ms/step - loss: 9.7452 - mae: 9.7452\n",
            "Epoch 24/300\n",
            "1/1 - 0s - 27ms/step - loss: 9.7291 - mae: 9.7291\n",
            "Epoch 25/300\n",
            "1/1 - 0s - 27ms/step - loss: 9.7063 - mae: 9.7063\n",
            "Epoch 26/300\n",
            "1/1 - 0s - 30ms/step - loss: 9.6776 - mae: 9.6776\n",
            "Epoch 27/300\n",
            "1/1 - 0s - 53ms/step - loss: 9.6595 - mae: 9.6595\n",
            "Epoch 28/300\n",
            "1/1 - 0s - 58ms/step - loss: 9.6466 - mae: 9.6466\n",
            "Epoch 29/300\n",
            "1/1 - 0s - 33ms/step - loss: 9.6307 - mae: 9.6307\n",
            "Epoch 30/300\n",
            "1/1 - 0s - 39ms/step - loss: 9.6120 - mae: 9.6120\n",
            "Epoch 31/300\n",
            "1/1 - 0s - 37ms/step - loss: 9.5908 - mae: 9.5908\n",
            "Epoch 32/300\n",
            "1/1 - 0s - 59ms/step - loss: 9.5675 - mae: 9.5675\n",
            "Epoch 33/300\n",
            "1/1 - 0s - 56ms/step - loss: 9.5422 - mae: 9.5422\n",
            "Epoch 34/300\n",
            "1/1 - 0s - 59ms/step - loss: 9.5295 - mae: 9.5295\n",
            "Epoch 35/300\n",
            "1/1 - 0s - 29ms/step - loss: 9.5158 - mae: 9.5158\n",
            "Epoch 36/300\n",
            "1/1 - 0s - 30ms/step - loss: 9.4947 - mae: 9.4947\n",
            "Epoch 37/300\n",
            "1/1 - 0s - 32ms/step - loss: 9.4668 - mae: 9.4668\n",
            "Epoch 38/300\n",
            "1/1 - 0s - 28ms/step - loss: 9.4498 - mae: 9.4498\n",
            "Epoch 39/300\n",
            "1/1 - 0s - 28ms/step - loss: 9.4357 - mae: 9.4357\n",
            "Epoch 40/300\n",
            "1/1 - 0s - 27ms/step - loss: 9.4187 - mae: 9.4187\n",
            "Epoch 41/300\n",
            "1/1 - 0s - 29ms/step - loss: 9.3992 - mae: 9.3992\n",
            "Epoch 42/300\n",
            "1/1 - 0s - 29ms/step - loss: 9.3773 - mae: 9.3773\n",
            "Epoch 43/300\n",
            "1/1 - 0s - 33ms/step - loss: 9.3533 - mae: 9.3533\n",
            "Epoch 44/300\n",
            "1/1 - 0s - 28ms/step - loss: 9.3275 - mae: 9.3275\n",
            "Epoch 45/300\n",
            "1/1 - 0s - 31ms/step - loss: 9.3195 - mae: 9.3195\n",
            "Epoch 46/300\n",
            "1/1 - 0s - 39ms/step - loss: 9.3052 - mae: 9.3052\n",
            "Epoch 47/300\n",
            "1/1 - 0s - 42ms/step - loss: 9.2829 - mae: 9.2829\n",
            "Epoch 48/300\n",
            "1/1 - 0s - 51ms/step - loss: 9.2532 - mae: 9.2532\n",
            "Epoch 49/300\n",
            "1/1 - 0s - 41ms/step - loss: 9.2331 - mae: 9.2331\n",
            "Epoch 50/300\n",
            "1/1 - 0s - 59ms/step - loss: 9.2187 - mae: 9.2187\n",
            "Epoch 51/300\n",
            "1/1 - 0s - 61ms/step - loss: 9.2015 - mae: 9.2015\n",
            "Epoch 52/300\n",
            "1/1 - 0s - 135ms/step - loss: 9.1817 - mae: 9.1817\n",
            "Epoch 53/300\n",
            "1/1 - 0s - 70ms/step - loss: 9.1596 - mae: 9.1596\n",
            "Epoch 54/300\n",
            "1/1 - 0s - 42ms/step - loss: 9.1355 - mae: 9.1355\n",
            "Epoch 55/300\n",
            "1/1 - 0s - 59ms/step - loss: 9.1095 - mae: 9.1095\n",
            "Epoch 56/300\n",
            "1/1 - 0s - 38ms/step - loss: 9.0922 - mae: 9.0922\n",
            "Epoch 57/300\n",
            "1/1 - 0s - 56ms/step - loss: 9.0761 - mae: 9.0761\n",
            "Epoch 58/300\n",
            "1/1 - 0s - 44ms/step - loss: 9.0514 - mae: 9.0514\n",
            "Epoch 59/300\n",
            "1/1 - 0s - 60ms/step - loss: 9.0256 - mae: 9.0256\n",
            "Epoch 60/300\n",
            "1/1 - 0s - 54ms/step - loss: 9.0079 - mae: 9.0079\n",
            "Epoch 61/300\n",
            "1/1 - 0s - 58ms/step - loss: 8.9877 - mae: 8.9877\n",
            "Epoch 62/300\n",
            "1/1 - 0s - 57ms/step - loss: 8.9652 - mae: 8.9652\n",
            "Epoch 63/300\n",
            "1/1 - 0s - 53ms/step - loss: 8.9408 - mae: 8.9408\n",
            "Epoch 64/300\n",
            "1/1 - 0s - 50ms/step - loss: 8.9246 - mae: 8.9246\n",
            "Epoch 65/300\n",
            "1/1 - 0s - 55ms/step - loss: 8.9039 - mae: 8.9039\n",
            "Epoch 66/300\n",
            "1/1 - 0s - 61ms/step - loss: 8.8750 - mae: 8.8750\n",
            "Epoch 67/300\n",
            "1/1 - 0s - 50ms/step - loss: 8.8548 - mae: 8.8548\n",
            "Epoch 68/300\n",
            "1/1 - 0s - 57ms/step - loss: 8.8323 - mae: 8.8323\n",
            "Epoch 69/300\n",
            "1/1 - 0s - 59ms/step - loss: 8.8138 - mae: 8.8138\n",
            "Epoch 70/300\n",
            "1/1 - 0s - 67ms/step - loss: 8.7882 - mae: 8.7882\n",
            "Epoch 71/300\n",
            "1/1 - 0s - 40ms/step - loss: 8.7711 - mae: 8.7711\n",
            "Epoch 72/300\n",
            "1/1 - 0s - 60ms/step - loss: 8.7519 - mae: 8.7519\n",
            "Epoch 73/300\n",
            "1/1 - 0s - 40ms/step - loss: 8.7304 - mae: 8.7304\n",
            "Epoch 74/300\n",
            "1/1 - 0s - 54ms/step - loss: 8.7066 - mae: 8.7066\n",
            "Epoch 75/300\n",
            "1/1 - 0s - 54ms/step - loss: 8.6809 - mae: 8.6809\n",
            "Epoch 76/300\n",
            "1/1 - 0s - 60ms/step - loss: 8.6534 - mae: 8.6534\n",
            "Epoch 77/300\n",
            "1/1 - 0s - 39ms/step - loss: 8.6434 - mae: 8.6434\n",
            "Epoch 78/300\n",
            "1/1 - 0s - 51ms/step - loss: 8.6235 - mae: 8.6235\n",
            "Epoch 79/300\n",
            "1/1 - 0s - 60ms/step - loss: 8.5939 - mae: 8.5939\n",
            "Epoch 80/300\n",
            "1/1 - 0s - 57ms/step - loss: 8.5634 - mae: 8.5634\n",
            "Epoch 81/300\n",
            "1/1 - 0s - 56ms/step - loss: 8.5441 - mae: 8.5441\n",
            "Epoch 82/300\n",
            "1/1 - 0s - 57ms/step - loss: 8.5224 - mae: 8.5224\n",
            "Epoch 83/300\n",
            "1/1 - 0s - 60ms/step - loss: 8.4984 - mae: 8.4984\n",
            "Epoch 84/300\n",
            "1/1 - 0s - 63ms/step - loss: 8.4723 - mae: 8.4723\n",
            "Epoch 85/300\n",
            "1/1 - 0s - 52ms/step - loss: 8.4445 - mae: 8.4445\n",
            "Epoch 86/300\n",
            "1/1 - 0s - 60ms/step - loss: 8.4247 - mae: 8.4247\n",
            "Epoch 87/300\n",
            "1/1 - 0s - 59ms/step - loss: 8.4015 - mae: 8.4015\n",
            "Epoch 88/300\n",
            "1/1 - 0s - 54ms/step - loss: 8.3693 - mae: 8.3693\n",
            "Epoch 89/300\n",
            "1/1 - 0s - 58ms/step - loss: 8.3461 - mae: 8.3461\n",
            "Epoch 90/300\n",
            "1/1 - 0s - 58ms/step - loss: 8.3207 - mae: 8.3207\n",
            "Epoch 91/300\n",
            "1/1 - 0s - 42ms/step - loss: 8.2965 - mae: 8.2965\n",
            "Epoch 92/300\n",
            "1/1 - 0s - 56ms/step - loss: 8.2703 - mae: 8.2703\n",
            "Epoch 93/300\n",
            "1/1 - 0s - 55ms/step - loss: 8.2450 - mae: 8.2450\n",
            "Epoch 94/300\n",
            "1/1 - 0s - 58ms/step - loss: 8.2187 - mae: 8.2187\n",
            "Epoch 95/300\n",
            "1/1 - 0s - 46ms/step - loss: 8.1946 - mae: 8.1946\n",
            "Epoch 96/300\n",
            "1/1 - 0s - 28ms/step - loss: 8.1692 - mae: 8.1692\n",
            "Epoch 97/300\n",
            "1/1 - 0s - 29ms/step - loss: 8.1417 - mae: 8.1417\n",
            "Epoch 98/300\n",
            "1/1 - 0s - 30ms/step - loss: 8.1162 - mae: 8.1162\n",
            "Epoch 99/300\n",
            "1/1 - 0s - 33ms/step - loss: 8.0875 - mae: 8.0875\n",
            "Epoch 100/300\n",
            "1/1 - 0s - 54ms/step - loss: 8.0603 - mae: 8.0603\n",
            "Epoch 101/300\n",
            "1/1 - 0s - 33ms/step - loss: 8.0374 - mae: 8.0374\n",
            "Epoch 102/300\n",
            "1/1 - 0s - 54ms/step - loss: 8.0065 - mae: 8.0065\n",
            "Epoch 103/300\n",
            "1/1 - 0s - 28ms/step - loss: 7.9794 - mae: 7.9794\n",
            "Epoch 104/300\n",
            "1/1 - 0s - 26ms/step - loss: 7.9513 - mae: 7.9513\n",
            "Epoch 105/300\n",
            "1/1 - 0s - 56ms/step - loss: 7.9255 - mae: 7.9255\n",
            "Epoch 106/300\n",
            "1/1 - 0s - 60ms/step - loss: 7.8983 - mae: 7.8983\n",
            "Epoch 107/300\n",
            "1/1 - 0s - 54ms/step - loss: 7.8690 - mae: 7.8690\n",
            "Epoch 108/300\n",
            "1/1 - 0s - 29ms/step - loss: 7.8378 - mae: 7.8378\n",
            "Epoch 109/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.8179 - mae: 7.8179\n",
            "Epoch 110/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.7869 - mae: 7.7869\n",
            "Epoch 111/300\n",
            "1/1 - 0s - 28ms/step - loss: 7.7522 - mae: 7.7522\n",
            "Epoch 112/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.7253 - mae: 7.7253\n",
            "Epoch 113/300\n",
            "1/1 - 0s - 26ms/step - loss: 7.6962 - mae: 7.6962\n",
            "Epoch 114/300\n",
            "1/1 - 0s - 29ms/step - loss: 7.6649 - mae: 7.6649\n",
            "Epoch 115/300\n",
            "1/1 - 0s - 58ms/step - loss: 7.6317 - mae: 7.6317\n",
            "Epoch 116/300\n",
            "1/1 - 0s - 28ms/step - loss: 7.6050 - mae: 7.6050\n",
            "Epoch 117/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.5721 - mae: 7.5721\n",
            "Epoch 118/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.5403 - mae: 7.5403\n",
            "Epoch 119/300\n",
            "1/1 - 0s - 29ms/step - loss: 7.5116 - mae: 7.5116\n",
            "Epoch 120/300\n",
            "1/1 - 0s - 56ms/step - loss: 7.4805 - mae: 7.4805\n",
            "Epoch 121/300\n",
            "1/1 - 0s - 33ms/step - loss: 7.4473 - mae: 7.4473\n",
            "Epoch 122/300\n",
            "1/1 - 0s - 39ms/step - loss: 7.4121 - mae: 7.4121\n",
            "Epoch 123/300\n",
            "1/1 - 0s - 35ms/step - loss: 7.3771 - mae: 7.3771\n",
            "Epoch 124/300\n",
            "1/1 - 0s - 55ms/step - loss: 7.3430 - mae: 7.3430\n",
            "Epoch 125/300\n",
            "1/1 - 0s - 57ms/step - loss: 7.3108 - mae: 7.3108\n",
            "Epoch 126/300\n",
            "1/1 - 0s - 34ms/step - loss: 7.2785 - mae: 7.2785\n",
            "Epoch 127/300\n",
            "1/1 - 0s - 30ms/step - loss: 7.2480 - mae: 7.2480\n",
            "Epoch 128/300\n",
            "1/1 - 0s - 30ms/step - loss: 7.2318 - mae: 7.2318\n",
            "Epoch 129/300\n",
            "1/1 - 0s - 28ms/step - loss: 7.2159 - mae: 7.2159\n",
            "Epoch 130/300\n",
            "1/1 - 0s - 58ms/step - loss: 7.2000 - mae: 7.2000\n",
            "Epoch 131/300\n",
            "1/1 - 0s - 57ms/step - loss: 7.1843 - mae: 7.1843\n",
            "Epoch 132/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.1727 - mae: 7.1727\n",
            "Epoch 133/300\n",
            "1/1 - 0s - 56ms/step - loss: 7.1563 - mae: 7.1563\n",
            "Epoch 134/300\n",
            "1/1 - 0s - 35ms/step - loss: 7.1437 - mae: 7.1437\n",
            "Epoch 135/300\n",
            "1/1 - 0s - 58ms/step - loss: 7.1308 - mae: 7.1308\n",
            "Epoch 136/300\n",
            "1/1 - 0s - 28ms/step - loss: 7.1178 - mae: 7.1178\n",
            "Epoch 137/300\n",
            "1/1 - 0s - 29ms/step - loss: 7.1045 - mae: 7.1045\n",
            "Epoch 138/300\n",
            "1/1 - 0s - 58ms/step - loss: 7.0910 - mae: 7.0910\n",
            "Epoch 139/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.0793 - mae: 7.0793\n",
            "Epoch 140/300\n",
            "1/1 - 0s - 27ms/step - loss: 7.0668 - mae: 7.0668\n",
            "Epoch 141/300\n",
            "1/1 - 0s - 29ms/step - loss: 7.0557 - mae: 7.0557\n",
            "Epoch 142/300\n",
            "1/1 - 0s - 28ms/step - loss: 7.0442 - mae: 7.0442\n",
            "Epoch 143/300\n",
            "1/1 - 0s - 59ms/step - loss: 7.0323 - mae: 7.0323\n",
            "Epoch 144/300\n",
            "1/1 - 0s - 34ms/step - loss: 7.0199 - mae: 7.0199\n",
            "Epoch 145/300\n",
            "1/1 - 0s - 37ms/step - loss: 7.0072 - mae: 7.0072\n",
            "Epoch 146/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.9942 - mae: 6.9942\n",
            "Epoch 147/300\n",
            "1/1 - 0s - 57ms/step - loss: 6.9870 - mae: 6.9870\n",
            "Epoch 148/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.9706 - mae: 6.9706\n",
            "Epoch 149/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.9598 - mae: 6.9598\n",
            "Epoch 150/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.9484 - mae: 6.9484\n",
            "Epoch 151/300\n",
            "1/1 - 0s - 26ms/step - loss: 6.9364 - mae: 6.9364\n",
            "Epoch 152/300\n",
            "1/1 - 0s - 26ms/step - loss: 6.9240 - mae: 6.9240\n",
            "Epoch 153/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.9111 - mae: 6.9111\n",
            "Epoch 154/300\n",
            "1/1 - 0s - 29ms/step - loss: 6.9046 - mae: 6.9046\n",
            "Epoch 155/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.8877 - mae: 6.8877\n",
            "Epoch 156/300\n",
            "1/1 - 0s - 57ms/step - loss: 6.8768 - mae: 6.8768\n",
            "Epoch 157/300\n",
            "1/1 - 0s - 29ms/step - loss: 6.8653 - mae: 6.8653\n",
            "Epoch 158/300\n",
            "1/1 - 0s - 29ms/step - loss: 6.8532 - mae: 6.8532\n",
            "Epoch 159/300\n",
            "1/1 - 0s - 58ms/step - loss: 6.8406 - mae: 6.8406\n",
            "Epoch 160/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.8274 - mae: 6.8274\n",
            "Epoch 161/300\n",
            "1/1 - 0s - 30ms/step - loss: 6.8138 - mae: 6.8138\n",
            "Epoch 162/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.8103 - mae: 6.8103\n",
            "Epoch 163/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.7888 - mae: 6.7888\n",
            "Epoch 164/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.7772 - mae: 6.7772\n",
            "Epoch 165/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.7650 - mae: 6.7650\n",
            "Epoch 166/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.7521 - mae: 6.7521\n",
            "Epoch 167/300\n",
            "1/1 - 0s - 57ms/step - loss: 6.7386 - mae: 6.7386\n",
            "Epoch 168/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.7246 - mae: 6.7246\n",
            "Epoch 169/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.7199 - mae: 6.7199\n",
            "Epoch 170/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.6988 - mae: 6.6988\n",
            "Epoch 171/300\n",
            "1/1 - 0s - 55ms/step - loss: 6.6867 - mae: 6.6867\n",
            "Epoch 172/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.6740 - mae: 6.6740\n",
            "Epoch 173/300\n",
            "1/1 - 0s - 26ms/step - loss: 6.6605 - mae: 6.6605\n",
            "Epoch 174/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.6464 - mae: 6.6464\n",
            "Epoch 175/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.6318 - mae: 6.6318\n",
            "Epoch 176/300\n",
            "1/1 - 0s - 30ms/step - loss: 6.6166 - mae: 6.6166\n",
            "Epoch 177/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.6133 - mae: 6.6133\n",
            "Epoch 178/300\n",
            "1/1 - 0s - 37ms/step - loss: 6.5886 - mae: 6.5886\n",
            "Epoch 179/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.5755 - mae: 6.5755\n",
            "Epoch 180/300\n",
            "1/1 - 0s - 26ms/step - loss: 6.5616 - mae: 6.5616\n",
            "Epoch 181/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.5470 - mae: 6.5470\n",
            "Epoch 182/300\n",
            "1/1 - 0s - 32ms/step - loss: 6.5318 - mae: 6.5318\n",
            "Epoch 183/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.5160 - mae: 6.5160\n",
            "Epoch 184/300\n",
            "1/1 - 0s - 29ms/step - loss: 6.5102 - mae: 6.5102\n",
            "Epoch 185/300\n",
            "1/1 - 0s - 29ms/step - loss: 6.4867 - mae: 6.4867\n",
            "Epoch 186/300\n",
            "1/1 - 0s - 30ms/step - loss: 6.4730 - mae: 6.4730\n",
            "Epoch 187/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.4584 - mae: 6.4584\n",
            "Epoch 188/300\n",
            "1/1 - 0s - 59ms/step - loss: 6.4430 - mae: 6.4430\n",
            "Epoch 189/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.4270 - mae: 6.4270\n",
            "Epoch 190/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.4104 - mae: 6.4104\n",
            "Epoch 191/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.3932 - mae: 6.3932\n",
            "Epoch 192/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.3879 - mae: 6.3879\n",
            "Epoch 193/300\n",
            "1/1 - 0s - 35ms/step - loss: 6.3611 - mae: 6.3611\n",
            "Epoch 194/300\n",
            "1/1 - 0s - 37ms/step - loss: 6.3460 - mae: 6.3460\n",
            "Epoch 195/300\n",
            "1/1 - 0s - 33ms/step - loss: 6.3301 - mae: 6.3301\n",
            "Epoch 196/300\n",
            "1/1 - 0s - 34ms/step - loss: 6.3134 - mae: 6.3134\n",
            "Epoch 197/300\n",
            "1/1 - 0s - 53ms/step - loss: 6.2961 - mae: 6.2961\n",
            "Epoch 198/300\n",
            "1/1 - 0s - 33ms/step - loss: 6.2780 - mae: 6.2780\n",
            "Epoch 199/300\n",
            "1/1 - 0s - 33ms/step - loss: 6.2698 - mae: 6.2698\n",
            "Epoch 200/300\n",
            "1/1 - 0s - 29ms/step - loss: 6.2444 - mae: 6.2444\n",
            "Epoch 201/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.2285 - mae: 6.2285\n",
            "Epoch 202/300\n",
            "1/1 - 0s - 26ms/step - loss: 6.2116 - mae: 6.2116\n",
            "Epoch 203/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.1940 - mae: 6.1940\n",
            "Epoch 204/300\n",
            "1/1 - 0s - 58ms/step - loss: 6.1756 - mae: 6.1756\n",
            "Epoch 205/300\n",
            "1/1 - 0s - 29ms/step - loss: 6.1566 - mae: 6.1566\n",
            "Epoch 206/300\n",
            "1/1 - 0s - 57ms/step - loss: 6.1368 - mae: 6.1368\n",
            "Epoch 207/300\n",
            "1/1 - 0s - 30ms/step - loss: 6.1296 - mae: 6.1296\n",
            "Epoch 208/300\n",
            "1/1 - 0s - 28ms/step - loss: 6.0999 - mae: 6.0999\n",
            "Epoch 209/300\n",
            "1/1 - 0s - 52ms/step - loss: 6.0824 - mae: 6.0824\n",
            "Epoch 210/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.0640 - mae: 6.0640\n",
            "Epoch 211/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.0448 - mae: 6.0448\n",
            "Epoch 212/300\n",
            "1/1 - 0s - 27ms/step - loss: 6.0248 - mae: 6.0248\n",
            "Epoch 213/300\n",
            "1/1 - 0s - 56ms/step - loss: 6.0040 - mae: 6.0040\n",
            "Epoch 214/300\n",
            "1/1 - 0s - 30ms/step - loss: 6.0110 - mae: 6.0110\n",
            "Epoch 215/300\n",
            "1/1 - 0s - 37ms/step - loss: 5.9903 - mae: 5.9903\n",
            "Epoch 216/300\n",
            "1/1 - 0s - 56ms/step - loss: 5.9814 - mae: 5.9814\n",
            "Epoch 217/300\n",
            "1/1 - 0s - 37ms/step - loss: 5.9722 - mae: 5.9722\n",
            "Epoch 218/300\n",
            "1/1 - 0s - 55ms/step - loss: 5.9628 - mae: 5.9628\n",
            "Epoch 219/300\n",
            "1/1 - 0s - 54ms/step - loss: 5.9530 - mae: 5.9530\n",
            "Epoch 220/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.9431 - mae: 5.9431\n",
            "Epoch 221/300\n",
            "1/1 - 0s - 34ms/step - loss: 5.9329 - mae: 5.9329\n",
            "Epoch 222/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.9225 - mae: 5.9225\n",
            "Epoch 223/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.9119 - mae: 5.9119\n",
            "Epoch 224/300\n",
            "1/1 - 0s - 29ms/step - loss: 5.9011 - mae: 5.9011\n",
            "Epoch 225/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.8968 - mae: 5.8968\n",
            "Epoch 226/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.8914 - mae: 5.8914\n",
            "Epoch 227/300\n",
            "1/1 - 0s - 30ms/step - loss: 5.8836 - mae: 5.8836\n",
            "Epoch 228/300\n",
            "1/1 - 0s - 57ms/step - loss: 5.8736 - mae: 5.8736\n",
            "Epoch 229/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.8616 - mae: 5.8616\n",
            "Epoch 230/300\n",
            "1/1 - 0s - 29ms/step - loss: 5.8543 - mae: 5.8543\n",
            "Epoch 231/300\n",
            "1/1 - 0s - 26ms/step - loss: 5.8485 - mae: 5.8485\n",
            "Epoch 232/300\n",
            "1/1 - 0s - 55ms/step - loss: 5.8421 - mae: 5.8421\n",
            "Epoch 233/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.8349 - mae: 5.8349\n",
            "Epoch 234/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.8272 - mae: 5.8272\n",
            "Epoch 235/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.8189 - mae: 5.8189\n",
            "Epoch 236/300\n",
            "1/1 - 0s - 30ms/step - loss: 5.8100 - mae: 5.8100\n",
            "Epoch 237/300\n",
            "1/1 - 0s - 59ms/step - loss: 5.8008 - mae: 5.8008\n",
            "Epoch 238/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.7910 - mae: 5.7910\n",
            "Epoch 239/300\n",
            "1/1 - 0s - 36ms/step - loss: 5.7839 - mae: 5.7839\n",
            "Epoch 240/300\n",
            "1/1 - 0s - 38ms/step - loss: 5.7779 - mae: 5.7779\n",
            "Epoch 241/300\n",
            "1/1 - 0s - 54ms/step - loss: 5.7693 - mae: 5.7693\n",
            "Epoch 242/300\n",
            "1/1 - 0s - 36ms/step - loss: 5.7583 - mae: 5.7583\n",
            "Epoch 243/300\n",
            "1/1 - 0s - 56ms/step - loss: 5.7512 - mae: 5.7512\n",
            "Epoch 244/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.7434 - mae: 5.7434\n",
            "Epoch 245/300\n",
            "1/1 - 0s - 56ms/step - loss: 5.7350 - mae: 5.7350\n",
            "Epoch 246/300\n",
            "1/1 - 0s - 29ms/step - loss: 5.7277 - mae: 5.7277\n",
            "Epoch 247/300\n",
            "1/1 - 0s - 32ms/step - loss: 5.7190 - mae: 5.7190\n",
            "Epoch 248/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.7117 - mae: 5.7117\n",
            "Epoch 249/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.7044 - mae: 5.7044\n",
            "Epoch 250/300\n",
            "1/1 - 0s - 57ms/step - loss: 5.6963 - mae: 5.6963\n",
            "Epoch 251/300\n",
            "1/1 - 0s - 32ms/step - loss: 5.6875 - mae: 5.6875\n",
            "Epoch 252/300\n",
            "1/1 - 0s - 37ms/step - loss: 5.6782 - mae: 5.6782\n",
            "Epoch 253/300\n",
            "1/1 - 0s - 58ms/step - loss: 5.6718 - mae: 5.6718\n",
            "Epoch 254/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.6638 - mae: 5.6638\n",
            "Epoch 255/300\n",
            "1/1 - 0s - 32ms/step - loss: 5.6531 - mae: 5.6531\n",
            "Epoch 256/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.6464 - mae: 5.6464\n",
            "Epoch 257/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.6393 - mae: 5.6393\n",
            "Epoch 258/300\n",
            "1/1 - 0s - 26ms/step - loss: 5.6315 - mae: 5.6315\n",
            "Epoch 259/300\n",
            "1/1 - 0s - 26ms/step - loss: 5.6229 - mae: 5.6229\n",
            "Epoch 260/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.6135 - mae: 5.6135\n",
            "Epoch 261/300\n",
            "1/1 - 0s - 57ms/step - loss: 5.6036 - mae: 5.6036\n",
            "Epoch 262/300\n",
            "1/1 - 0s - 31ms/step - loss: 5.5930 - mae: 5.5930\n",
            "Epoch 263/300\n",
            "1/1 - 0s - 33ms/step - loss: 5.5872 - mae: 5.5872\n",
            "Epoch 264/300\n",
            "1/1 - 0s - 37ms/step - loss: 5.5798 - mae: 5.5798\n",
            "Epoch 265/300\n",
            "1/1 - 0s - 39ms/step - loss: 5.5693 - mae: 5.5693\n",
            "Epoch 266/300\n",
            "1/1 - 0s - 57ms/step - loss: 5.5571 - mae: 5.5571\n",
            "Epoch 267/300\n",
            "1/1 - 0s - 56ms/step - loss: 5.5492 - mae: 5.5492\n",
            "Epoch 268/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.5405 - mae: 5.5405\n",
            "Epoch 269/300\n",
            "1/1 - 0s - 29ms/step - loss: 5.5310 - mae: 5.5310\n",
            "Epoch 270/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.5207 - mae: 5.5207\n",
            "Epoch 271/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.5128 - mae: 5.5128\n",
            "Epoch 272/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.5039 - mae: 5.5039\n",
            "Epoch 273/300\n",
            "1/1 - 0s - 30ms/step - loss: 5.5043 - mae: 5.5043\n",
            "Epoch 274/300\n",
            "1/1 - 0s - 26ms/step - loss: 5.5063 - mae: 5.5063\n",
            "Epoch 275/300\n",
            "1/1 - 0s - 26ms/step - loss: 5.5064 - mae: 5.5064\n",
            "Epoch 276/300\n",
            "1/1 - 0s - 31ms/step - loss: 5.5049 - mae: 5.5049\n",
            "Epoch 277/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.5019 - mae: 5.5019\n",
            "Epoch 278/300\n",
            "1/1 - 0s - 59ms/step - loss: 5.4975 - mae: 5.4975\n",
            "Epoch 279/300\n",
            "1/1 - 0s - 29ms/step - loss: 5.4920 - mae: 5.4920\n",
            "Epoch 280/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.4906 - mae: 5.4906\n",
            "Epoch 281/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.4895 - mae: 5.4895\n",
            "Epoch 282/300\n",
            "1/1 - 0s - 30ms/step - loss: 5.4917 - mae: 5.4917\n",
            "Epoch 283/300\n",
            "1/1 - 0s - 30ms/step - loss: 5.4921 - mae: 5.4921\n",
            "Epoch 284/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.4908 - mae: 5.4908\n",
            "Epoch 285/300\n",
            "1/1 - 0s - 58ms/step - loss: 5.4880 - mae: 5.4880\n",
            "Epoch 286/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.4838 - mae: 5.4838\n",
            "Epoch 287/300\n",
            "1/1 - 0s - 60ms/step - loss: 5.4784 - mae: 5.4784\n",
            "Epoch 288/300\n",
            "1/1 - 0s - 36ms/step - loss: 5.5062 - mae: 5.5062\n",
            "Epoch 289/300\n",
            "1/1 - 0s - 56ms/step - loss: 5.4762 - mae: 5.4762\n",
            "Epoch 290/300\n",
            "1/1 - 0s - 56ms/step - loss: 5.4785 - mae: 5.4785\n",
            "Epoch 291/300\n",
            "1/1 - 0s - 39ms/step - loss: 5.4789 - mae: 5.4789\n",
            "Epoch 292/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.4777 - mae: 5.4777\n",
            "Epoch 293/300\n",
            "1/1 - 0s - 43ms/step - loss: 5.4750 - mae: 5.4750\n",
            "Epoch 294/300\n",
            "1/1 - 0s - 36ms/step - loss: 5.4708 - mae: 5.4708\n",
            "Epoch 295/300\n",
            "1/1 - 0s - 54ms/step - loss: 5.4973 - mae: 5.4973\n",
            "Epoch 296/300\n",
            "1/1 - 0s - 58ms/step - loss: 5.4708 - mae: 5.4708\n",
            "Epoch 297/300\n",
            "1/1 - 0s - 28ms/step - loss: 5.4740 - mae: 5.4740\n",
            "Epoch 298/300\n",
            "1/1 - 0s - 32ms/step - loss: 5.4753 - mae: 5.4753\n",
            "Epoch 299/300\n",
            "1/1 - 0s - 27ms/step - loss: 5.4748 - mae: 5.4748\n",
            "Epoch 300/300\n",
            "1/1 - 0s - 29ms/step - loss: 5.4728 - mae: 5.4728\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78e276eea530>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Sample data (10 samples of X)\n",
        "X = np.array([i for i in range(10)])  # 10 samples (0 to 9)\n",
        "Y = np.array([i**2 for i in range(10)])  # Corresponding Y values (Y = X^2)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=46)\n",
        "\n",
        "# Reshape X_train and X_test to be 2D arrays (required for TensorFlow)\n",
        "X_train = X_train.reshape(-1, 1)  # Reshape to (samples, features)\n",
        "X_test = X_test.reshape(-1, 1)    # Reshape to (samples, features)\n",
        "\n",
        "# Print the train and test sets\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"Y_train:\", Y_train)\n",
        "print(\"X_test:\", X_test)\n",
        "print(\"Y_test:\", Y_test)\n",
        "\n",
        "# Define the model\n",
        "mode_insured = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, input_shape=[1]),  # Input layer (1 feature)\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "mode_insured.compile(loss='mae',  # Mean Absolute Error\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "mode_insured.fit(X_train, Y_train, epochs=100, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "mode_insured.evaluate(X_test, Y_test)\n",
        "\n",
        "mode_insured.fit(X_train, Y_train, epochs=300, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "insured_model_2= tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "insured_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.Adam(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "history = insured_model_2.fit(X_train, Y_train, epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCLngb03mIFX",
        "outputId": "0bd85a25-d8d5-43f2-eaaf-1cd3ff051005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 29.7931 - mae: 29.7931\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 29.5288 - mae: 29.5288\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 29.2650 - mae: 29.2650\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 29.0016 - mae: 29.0016\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 28.7385 - mae: 28.7385\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 28.4756 - mae: 28.4756\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 28.2128 - mae: 28.2128\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 27.9499 - mae: 27.9499\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 27.6869 - mae: 27.6869\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 27.4234 - mae: 27.4234\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 27.1593 - mae: 27.1593\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 26.8943 - mae: 26.8943\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 26.6283 - mae: 26.6283\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 26.3608 - mae: 26.3608\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 26.0916 - mae: 26.0916\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 25.8205 - mae: 25.8205\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 25.5551 - mae: 25.5551\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 25.2981 - mae: 25.2981\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 25.0394 - mae: 25.0394\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 24.7787 - mae: 24.7787\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 24.5155 - mae: 24.5155\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 24.2496 - mae: 24.2496\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 23.9807 - mae: 23.9807\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 23.7084 - mae: 23.7084\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 23.4326 - mae: 23.4326\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 23.1529 - mae: 23.1529\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 22.8691 - mae: 22.8691\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 22.5809 - mae: 22.5809\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 22.2881 - mae: 22.2881\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 21.9904 - mae: 21.9904\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 21.6876 - mae: 21.6876\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 21.3795 - mae: 21.3795\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 21.0683 - mae: 21.0683\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 20.7907 - mae: 20.7907\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 20.5100 - mae: 20.5100\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 20.2260 - mae: 20.2260\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 19.9381 - mae: 19.9381\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 19.6461 - mae: 19.6461\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 19.3495 - mae: 19.3495\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 19.0482 - mae: 19.0482\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 18.7417 - mae: 18.7417\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 18.4297 - mae: 18.4297\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 18.1120 - mae: 18.1120\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 17.7883 - mae: 17.7883\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 17.4583 - mae: 17.4583\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 17.1218 - mae: 17.1218\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 16.8245 - mae: 16.8245\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 16.5492 - mae: 16.5492\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 16.2723 - mae: 16.2723\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 15.9932 - mae: 15.9932\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 15.7116 - mae: 15.7116\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 15.4268 - mae: 15.4268\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 15.1386 - mae: 15.1386\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 14.8465 - mae: 14.8465\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 14.5502 - mae: 14.5502\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 14.2494 - mae: 14.2494\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 13.9436 - mae: 13.9436\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 13.6591 - mae: 13.6591\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13.4517 - mae: 13.4517\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 13.2459 - mae: 13.2459\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 13.0410 - mae: 13.0410\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 12.8366 - mae: 12.8366\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 12.6323 - mae: 12.6323\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 12.4277 - mae: 12.4277\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 12.2223 - mae: 12.2223\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 12.0158 - mae: 12.0158\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 11.8078 - mae: 11.8078\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 11.5981 - mae: 11.5981\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 11.4258 - mae: 11.4258\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 11.3401 - mae: 11.3401\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 11.2569 - mae: 11.2569\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 11.1758 - mae: 11.1758\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 11.0967 - mae: 11.0967\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 11.0192 - mae: 11.0192\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 10.9431 - mae: 10.9431\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 10.8682 - mae: 10.8682\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10.7943 - mae: 10.7943\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10.7212 - mae: 10.7212\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 10.6487 - mae: 10.6487\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 10.5767 - mae: 10.5767\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 10.5050 - mae: 10.5050\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10.4334 - mae: 10.4334\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10.4171 - mae: 10.4171\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 10.4354 - mae: 10.4354\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10.4470 - mae: 10.4470\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 10.4525 - mae: 10.4525\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10.4524 - mae: 10.4524\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 10.4474 - mae: 10.4474\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 10.4379 - mae: 10.4379\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.4245 - mae: 10.4245\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 10.4075 - mae: 10.4075\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 10.3873 - mae: 10.3873\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 10.3644 - mae: 10.3644\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 10.3391 - mae: 10.3391\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 10.3115 - mae: 10.3115\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 10.2821 - mae: 10.2821\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10.2510 - mae: 10.2510\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 10.2185 - mae: 10.2185\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 10.1848 - mae: 10.1848\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 10.1500 - mae: 10.1500\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 10.1143 - mae: 10.1143\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 10.0779 - mae: 10.0779\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 10.0408 - mae: 10.0408\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 10.0135 - mae: 10.0135\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 10.0156 - mae: 10.0156\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 10.0102 - mae: 10.0102\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 9.9981 - mae: 9.9981\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.9797 - mae: 9.9797\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.9557 - mae: 9.9557\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 9.9266 - mae: 9.9266\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 9.8926 - mae: 9.8926\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 9.8670 - mae: 9.8670\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 9.8580 - mae: 9.8580\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 9.8455 - mae: 9.8455\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.8300 - mae: 9.8300\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 9.8117 - mae: 9.8117\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 9.7909 - mae: 9.7909\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 9.7679 - mae: 9.7679\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 9.7430 - mae: 9.7430\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 9.7164 - mae: 9.7164\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 9.7127 - mae: 9.7127\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 9.7027 - mae: 9.7027\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 9.6854 - mae: 9.6854\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 9.6616 - mae: 9.6616\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.6317 - mae: 9.6317\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.6111 - mae: 9.6111\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 9.5993 - mae: 9.5993\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 9.5844 - mae: 9.5844\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.5668 - mae: 9.5668\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 9.5467 - mae: 9.5467\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 9.5245 - mae: 9.5245\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 9.5003 - mae: 9.5003\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 9.4774 - mae: 9.4774\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.4631 - mae: 9.4631\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 9.4414 - mae: 9.4414\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.4228 - mae: 9.4228\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.4066 - mae: 9.4066\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 9.3879 - mae: 9.3879\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 9.3439 - mae: 9.3439\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 9.3347 - mae: 9.3347\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.3179 - mae: 9.3179\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.2934 - mae: 9.2934\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.2700 - mae: 9.2700\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 9.2545 - mae: 9.2545\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.2364 - mae: 9.2364\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.2160 - mae: 9.2160\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9.1935 - mae: 9.1935\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.1725 - mae: 9.1725\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 9.1536 - mae: 9.1536\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.1335 - mae: 9.1335\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9.1151 - mae: 9.1151\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.0944 - mae: 9.0944\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.0723 - mae: 9.0723\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.0533 - mae: 9.0533\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.0326 - mae: 9.0326\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 9.0163 - mae: 9.0163\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8.9928 - mae: 8.9928\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 8.9768 - mae: 8.9768\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8.9594 - mae: 8.9594\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.9397 - mae: 8.9397\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 8.9179 - mae: 8.9179\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 8.8941 - mae: 8.8941\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.8711 - mae: 8.8711\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.8509 - mae: 8.8509\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8.8308 - mae: 8.8308\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.8113 - mae: 8.8113\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.7898 - mae: 8.7898\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.7663 - mae: 8.7663\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.7498 - mae: 8.7498\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.7276 - mae: 8.7276\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.7033 - mae: 8.7033\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.6839 - mae: 8.6839\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.6624 - mae: 8.6624\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.6388 - mae: 8.6388\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.6166 - mae: 8.6166\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 8.5926 - mae: 8.5926\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.5725 - mae: 8.5725\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 8.5507 - mae: 8.5507\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8.5295 - mae: 8.5295\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8.5063 - mae: 8.5063\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8.4812 - mae: 8.4812\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.4675 - mae: 8.4675\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8.4436 - mae: 8.4436\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 8.4139 - mae: 8.4139\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.3931 - mae: 8.3931\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8.3702 - mae: 8.3702\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.3455 - mae: 8.3455\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8.3212 - mae: 8.3212\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8.2967 - mae: 8.2967\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.2725 - mae: 8.2725\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8.2528 - mae: 8.2528\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.2246 - mae: 8.2246\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 8.2007 - mae: 8.2007\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.1773 - mae: 8.1773\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.1531 - mae: 8.1531\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 8.1293 - mae: 8.1293\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.1035 - mae: 8.1035\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 8.0768 - mae: 8.0768\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 8.0527 - mae: 8.0527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UYZuJl9VQFfS",
        "outputId": "60cf0031-12fa-4b18-cd46-7b5e8cafcafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cf31061-83eb-4933-ad62-778deccfc0b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cf31061-83eb-4933-ad62-778deccfc0b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cf31061-83eb-4933-ad62-778deccfc0b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cf31061-83eb-4933-ad62-778deccfc0b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3d68e4f-ebac-4c26-ae77-8699f85efed5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3d68e4f-ebac-4c26-ae77-8699f85efed5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3d68e4f-ebac-4c26-ae77-8699f85efed5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5bb03100-8578-4a8e-a2a6-0231f8a7f0a2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('insurance')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5bb03100-8578-4a8e-a2a6-0231f8a7f0a2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('insurance');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "insurance",
              "summary": "{\n  \"name\": \"insurance\",\n  \"rows\": 1338,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          21,\n          45,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.098186911679017,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 548,\n        \"samples\": [\n          23.18,\n          26.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"southeast\",\n          \"northeast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12110.011236693994,\n        \"min\": 1121.8739,\n        \"max\": 63770.42801,\n        \"num_unique_values\": 1337,\n        \"samples\": [\n          8688.85885,\n          5708.867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "ct =  make_column_transformer(\n",
        "    (MinMaxScaler(),[\"age\",\"bmi\",\"children\"]),\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"),[\"sex\",\"smoker\",\"region\"])\n",
        "\n",
        "    )\n",
        "X = insurance.drop(\"charges\",axis=1)\n",
        "Y= insurance[\"charges\"]\n",
        "\n",
        "X_train , X_test , Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)\n",
        "ct.fit(X_train)\n",
        "\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "metadata": {
        "id": "SdJWMPa1Qi8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Set seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define the model using Dense layers with activation functions\n",
        "very_insured_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),  # First hidden layer with 100 neurons\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\"),   # Second hidden layer with 10 neurons\n",
        "    tf.keras.layers.Dense(1)                        # Output layer with 1 neuron (for regression)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "very_insured_model.compile(loss=tf.keras.losses.mae,\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model on the transformed training data\n",
        "very_insured_model.fit(X_train_normal, Y_train, epochs=100)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERm-F2upbFwz",
        "outputId": "c860b5ea-7f36-400e-e160-ba655ab786db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13297.7832 - mae: 13297.7832\n",
            "Epoch 2/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13294.0596 - mae: 13294.0596\n",
            "Epoch 3/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13284.0840 - mae: 13284.0840\n",
            "Epoch 4/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13261.8584 - mae: 13261.8584\n",
            "Epoch 5/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13220.9795 - mae: 13220.9795\n",
            "Epoch 6/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13153.8633 - mae: 13153.8633\n",
            "Epoch 7/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13052.6748 - mae: 13052.6748\n",
            "Epoch 8/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12911.1436 - mae: 12911.1436\n",
            "Epoch 9/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12723.2568 - mae: 12723.2568\n",
            "Epoch 10/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12482.5508 - mae: 12482.5508\n",
            "Epoch 11/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12183.2705 - mae: 12183.2705\n",
            "Epoch 12/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11824.1182 - mae: 11824.1182\n",
            "Epoch 13/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11411.4131 - mae: 11411.4131 \n",
            "Epoch 14/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10975.0488 - mae: 10975.0488\n",
            "Epoch 15/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10541.2256 - mae: 10541.2256\n",
            "Epoch 16/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10106.1328 - mae: 10106.1328 \n",
            "Epoch 17/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9679.6260 - mae: 9679.6260 \n",
            "Epoch 18/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9283.1289 - mae: 9283.1289\n",
            "Epoch 19/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8930.9209 - mae: 8930.9209 \n",
            "Epoch 20/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8630.6006 - mae: 8630.6006 \n",
            "Epoch 21/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8386.3525 - mae: 8386.3525 \n",
            "Epoch 22/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8199.3799 - mae: 8199.3799\n",
            "Epoch 23/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8057.7837 - mae: 8057.7837\n",
            "Epoch 24/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7951.4341 - mae: 7951.4341 \n",
            "Epoch 25/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7873.8853 - mae: 7873.8853 \n",
            "Epoch 26/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7813.5815 - mae: 7813.5815\n",
            "Epoch 27/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7764.2998 - mae: 7764.2998 \n",
            "Epoch 28/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7719.8013 - mae: 7719.8013\n",
            "Epoch 29/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7678.6143 - mae: 7678.6143 \n",
            "Epoch 30/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7639.1069 - mae: 7639.1069\n",
            "Epoch 31/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7600.1230 - mae: 7600.1230 \n",
            "Epoch 32/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7561.5723 - mae: 7561.5723 \n",
            "Epoch 33/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7524.0439 - mae: 7524.0439 \n",
            "Epoch 34/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7486.5508 - mae: 7486.5508 \n",
            "Epoch 35/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7449.0439 - mae: 7449.0439 \n",
            "Epoch 36/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7411.0308 - mae: 7411.0308\n",
            "Epoch 37/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7372.5586 - mae: 7372.5586 \n",
            "Epoch 38/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7333.4019 - mae: 7333.4019\n",
            "Epoch 39/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7293.4390 - mae: 7293.4390\n",
            "Epoch 40/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7252.6196 - mae: 7252.6196 \n",
            "Epoch 41/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7210.9458 - mae: 7210.9458 \n",
            "Epoch 42/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7168.2866 - mae: 7168.2866 \n",
            "Epoch 43/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7124.6416 - mae: 7124.6416 \n",
            "Epoch 44/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7079.8237 - mae: 7079.8237 \n",
            "Epoch 45/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7033.8159 - mae: 7033.8159\n",
            "Epoch 46/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6986.5308 - mae: 6986.5308\n",
            "Epoch 47/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6937.9204 - mae: 6937.9204\n",
            "Epoch 48/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6887.7837 - mae: 6887.7837 \n",
            "Epoch 49/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6835.8687 - mae: 6835.8687 \n",
            "Epoch 50/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6782.2886 - mae: 6782.2886 \n",
            "Epoch 51/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6726.8159 - mae: 6726.8159 \n",
            "Epoch 52/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6669.5171 - mae: 6669.5171 \n",
            "Epoch 53/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6610.0576 - mae: 6610.0576 \n",
            "Epoch 54/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6548.4150 - mae: 6548.4150\n",
            "Epoch 55/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6484.4976 - mae: 6484.4976 \n",
            "Epoch 56/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6418.0068 - mae: 6418.0068 \n",
            "Epoch 57/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6349.0469 - mae: 6349.0469 \n",
            "Epoch 58/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6277.4067 - mae: 6277.4067\n",
            "Epoch 59/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6202.8721 - mae: 6202.8721\n",
            "Epoch 60/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6125.2686 - mae: 6125.2686\n",
            "Epoch 61/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6044.4395 - mae: 6044.4395 \n",
            "Epoch 62/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5960.3442 - mae: 5960.3442\n",
            "Epoch 63/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5872.8555 - mae: 5872.8555\n",
            "Epoch 64/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5781.8716 - mae: 5781.8716 \n",
            "Epoch 65/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5687.4116 - mae: 5687.4116 \n",
            "Epoch 66/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5589.1274 - mae: 5589.1274\n",
            "Epoch 67/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5487.9346 - mae: 5487.9346 \n",
            "Epoch 68/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5388.5312 - mae: 5388.5312\n",
            "Epoch 69/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5284.8340 - mae: 5284.8340 \n",
            "Epoch 70/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5177.2754 - mae: 5177.2754 \n",
            "Epoch 71/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5069.7788 - mae: 5069.7788\n",
            "Epoch 72/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4960.0820 - mae: 4960.0820\n",
            "Epoch 73/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4846.7153 - mae: 4846.7153 \n",
            "Epoch 74/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4736.4399 - mae: 4736.4399 \n",
            "Epoch 75/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4626.9487 - mae: 4626.9487 \n",
            "Epoch 76/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4519.4746 - mae: 4519.4746\n",
            "Epoch 77/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4418.1177 - mae: 4418.1177\n",
            "Epoch 78/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4325.0679 - mae: 4325.0679\n",
            "Epoch 79/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4237.3262 - mae: 4237.3262\n",
            "Epoch 80/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4155.5029 - mae: 4155.5029\n",
            "Epoch 81/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4078.2981 - mae: 4078.2981\n",
            "Epoch 82/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4006.4058 - mae: 4006.4058\n",
            "Epoch 83/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3939.6140 - mae: 3939.6140 \n",
            "Epoch 84/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3877.2871 - mae: 3877.2871\n",
            "Epoch 85/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3820.9006 - mae: 3820.9006\n",
            "Epoch 86/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3774.0708 - mae: 3774.0708 \n",
            "Epoch 87/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3734.3113 - mae: 3734.3113\n",
            "Epoch 88/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3701.8953 - mae: 3701.8953\n",
            "Epoch 89/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3677.2546 - mae: 3677.2546 \n",
            "Epoch 90/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3658.2258 - mae: 3658.2258 \n",
            "Epoch 91/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3643.4729 - mae: 3643.4729\n",
            "Epoch 92/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3631.9060 - mae: 3631.9060 \n",
            "Epoch 93/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3622.2964 - mae: 3622.2964\n",
            "Epoch 94/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3615.7190 - mae: 3615.7190\n",
            "Epoch 95/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3608.8687 - mae: 3608.8687\n",
            "Epoch 96/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3603.0898 - mae: 3603.0898\n",
            "Epoch 97/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3597.5154 - mae: 3597.5154\n",
            "Epoch 98/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3592.5544 - mae: 3592.5544\n",
            "Epoch 99/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3587.6704 - mae: 3587.6704\n",
            "Epoch 100/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3582.9583 - mae: 3582.9583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d9920de57b0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.loc[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "MzCSbinqRhnG",
        "outputId": "54fbf848-6e02-426a-9081-514e6e37b2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                60\n",
              "sex            female\n",
              "bmi             25.84\n",
              "children            0\n",
              "smoker             no\n",
              "region      northwest\n",
              "Name: 9, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bmi</th>\n",
              "      <td>25.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoker</th>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region</th>\n",
              "      <td>northwest</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normal[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os2XCDPeV4-L",
        "outputId": "0e07ea5c-8153-412b-eed9-f997efa7d6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.41304348, 0.49071832, 0.2       , 0.        , 1.        ,\n",
              "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}